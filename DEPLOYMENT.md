# Politico Web - Deployment Guide

This project is now deployment-ready with a clean, simplified Docker Compose structure.

## ğŸš€ Quick Start

### Development
```bash
# Simply run:
docker compose up -d

# Or use the helper script:
./start.sh dev -d
```

Access the application:
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- Admin Panel: http://localhost:8000/admin

### Production
```bash
# Run production build:
docker compose -f docker-compose.prod.yml up -d --build

# Or use the helper script:
./start.sh prod
```

Access the application:
- Application: http://localhost
- Admin Panel: http://localhost/admin

## ğŸ“ Project Structure

```
politico_web/
â”œâ”€â”€ backend/              # Django backend
â”œâ”€â”€ frontend/             # React frontend
â”œâ”€â”€ nginx/                # Nginx configuration (production)
â”œâ”€â”€ docker-compose.yml    # Development configuration
â”œâ”€â”€ docker-compose.prod.yml # Production configuration
â”œâ”€â”€ start.sh              # Helper script for common tasks
â”œâ”€â”€ run_scrapers_docker.sh # Data scraping utility
â”œâ”€â”€ env.example           # Environment variables template
â””â”€â”€ DEPLOYMENT.md         # This file
```

## ğŸ› ï¸ Configuration

### Environment Setup

1. Copy the environment template:
```bash
cp env.example .env
```

2. Edit `.env` with your settings:
```bash
# Database
DB_NAME=politico_db
DB_USER=politico_user
DB_PASSWORD=your_secure_password

# Django
SECRET_KEY=your_secret_key
DEBUG=False
ALLOWED_HOSTS=localhost,yourdomain.com

# Other settings...
```

## ğŸ“‹ Helper Script Commands

The `start.sh` script provides convenient commands:

```bash
# Development
./start.sh dev              # Start dev environment (foreground)
./start.sh dev -d           # Start dev environment (detached)

# Production
./start.sh prod             # Start production environment

# Management
./start.sh stop             # Stop all services
./start.sh status           # Show service status
./start.sh logs [service]   # View logs
./start.sh clean            # Remove all containers and volumes

# Django Commands
./start.sh django migrate           # Run migrations
./start.sh django createsuperuser   # Create admin user
./start.sh django collectstatic     # Collect static files

# Data Scraping
./start.sh scrapers 157     # Run scrapers for session 157
```

## ğŸ”„ Development Workflow

### Initial Setup
```bash
# 1. Clone the repository
git clone <your-repo>
cd politico_web

# 2. Set up environment
cp env.example .env
# Edit .env with your settings

# 3. Start services
docker compose up -d

# 4. Run migrations
./start.sh django migrate

# 5. Create admin user
./start.sh django createsuperuser

# 6. (Optional) Load data
./start.sh scrapers 157
```

### Daily Development
```bash
# Start services
docker compose up -d

# View logs
docker compose logs -f backend
docker compose logs -f frontend

# Stop services
docker compose down
```

## ğŸŒ Production Deployment

### Prerequisites
- Docker and Docker Compose installed
- Domain name configured (optional)
- SSL certificates (optional, for HTTPS)

### Deployment Steps

1. **Prepare the server:**
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Install Docker Compose
sudo apt install docker-compose-plugin
```

2. **Clone and configure:**
```bash
git clone <your-repo>
cd politico_web
cp env.example .env
# Edit .env with production settings
```

3. **Deploy:**
```bash
# Build and start
docker compose -f docker-compose.prod.yml up -d --build

# Run migrations
docker compose -f docker-compose.prod.yml exec backend python manage.py migrate

# Create superuser
docker compose -f docker-compose.prod.yml exec backend python manage.py createsuperuser

# Collect static files (if not done automatically)
docker compose -f docker-compose.prod.yml exec backend python manage.py collectstatic --noinput
```

4. **Load Initial Data (Scrapers):**

The database starts empty. You need to run the scrapers to populate it with parliamentary data:

```bash
# Run all scrapers for a specific session (e.g., session 157 for 2025-2026)
# Replace 157 with the current session number
docker compose -f docker-compose.prod.yml exec backend bash -c "
echo '1. Fetching Political Parties...'
python scrapers/fetch_parties.py 157
echo ''

echo '2. Fetching MPs...'
python scrapers/fetch_mps.py 157
echo ''

echo '3. Fetching Bills...'
python scrapers/fetch_bills.py 157
echo ''

echo '4. Assigning Topics...'
python scrapers/assign_topics.py
echo ''

echo '5. Fetching Voting Records...'
python scrapers/fetch_voting_records.py 157
echo ''

echo '6. Fetching Speeches...'
python scrapers/fetch_speeches.py 157
echo ''

echo '7. Fetching MP Interests...'
python scrapers/fetch_interests.py
echo ''

echo 'All done!'
"
```

**Note:** Replace `157` with the current AlÃ¾ingi session number. This process may take 10-30 minutes depending on the amount of data.

**Alternative:** You can also use the helper script (if available):
```bash
./start.sh scrapers 157
```

5. **Verify:**
```bash
# Check service status
docker compose -f docker-compose.prod.yml ps

# View logs
docker compose -f docker-compose.prod.yml logs -f
```

### Production Architecture

The production setup includes:
- **Nginx**: Reverse proxy and static file server (port 80/443)
- **Django + Gunicorn**: Backend API (internal)
- **React (built)**: Frontend served by Nginx
- **PostgreSQL**: Database
- **Redis**: Cache and Celery broker
- **Celery Workers**: Background tasks
- **Celery Beat**: Scheduled tasks

### SSL/HTTPS Configuration

To enable HTTPS:

1. Obtain SSL certificates (e.g., using Let's Encrypt):
```bash
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d yourdomain.com
```

2. Update `nginx/default.conf` to redirect HTTP to HTTPS

3. Update `.env`:
```bash
ALLOWED_HOSTS=yourdomain.com
REACT_APP_API_URL=https://yourdomain.com/api
```

## ğŸ”§ Maintenance

### Running Scrapers (Data Collection)

To update or populate the database with parliamentary data:

```bash
# Run all scrapers for a specific session
# Production:
docker compose -f docker-compose.prod.yml exec backend bash -c "
python scrapers/fetch_parties.py 157 &&
python scrapers/fetch_mps.py 157 &&
python scrapers/fetch_bills.py 157 &&
python scrapers/assign_topics.py &&
python scrapers/fetch_voting_records.py 157 &&
python scrapers/fetch_speeches.py 157 &&
python scrapers/fetch_interests.py
"

# Development:
docker compose exec backend bash -c "
python scrapers/fetch_parties.py 157 &&
python scrapers/fetch_mps.py 157 &&
python scrapers/fetch_bills.py 157 &&
python scrapers/assign_topics.py &&
python scrapers/fetch_voting_records.py 157 &&
python scrapers/fetch_speeches.py 157 &&
python scrapers/fetch_interests.py
"
```

**Individual Scrapers:**

You can also run scrapers individually:

```bash
# Production
docker compose -f docker-compose.prod.yml exec backend python scrapers/fetch_mps.py 157
docker compose -f docker-compose.prod.yml exec backend python scrapers/fetch_bills.py 157

# Development
docker compose exec backend python scrapers/fetch_mps.py 157
docker compose exec backend python scrapers/fetch_bills.py 157
```

**Check Current Session Number:**

The session number corresponds to the AlÃ¾ingi session. Common recent sessions:
- Session 157: 2025-2026
- Session 156: 2024-2025
- Session 155: 2023-2024

### Database Backup
```bash
# Create backup
docker compose exec db pg_dump -U politico_user politico_db > backup_$(date +%Y%m%d).sql

# Restore backup
docker compose exec -T db psql -U politico_user politico_db < backup_20240101.sql
```

### Update Application
```bash
# Pull latest changes
git pull

# Rebuild and restart (development)
docker compose up -d --build

# Rebuild and restart (production)
docker compose -f docker-compose.prod.yml up -d --build
```

### View Logs
```bash
# All services
docker compose logs -f

# Specific service
docker compose logs -f backend
docker compose logs -f celery_worker
```

### Scale Workers
```bash
# Scale Celery workers
docker compose -f docker-compose.prod.yml up -d --scale celery_worker=4
```

## ğŸ› Troubleshooting

### Services won't start
```bash
# Check Docker status
docker info

# Check service logs
docker compose logs

# Rebuild from scratch
docker compose down -v
docker compose build --no-cache
docker compose up -d
```

### Database connection errors
```bash
# Wait for database to be ready
docker compose exec backend python manage.py migrate

# Check database status
docker compose exec db pg_isready -U politico_user
```

### Port conflicts
```bash
# Change ports in docker-compose.yml or docker-compose.prod.yml
# Development: 3000 (frontend), 8000 (backend)
# Production: 80/443 (nginx)
```

## ğŸ“Š Monitoring

### Health Checks
```bash
# Check all services
docker compose ps

# Check specific service
docker compose exec backend python manage.py check
```

### Performance Monitoring
- Backend logs: `/backend/logs/django-error.log`
- Celery logs: `docker compose logs celery_worker`
- Database logs: `docker compose logs db`

## ğŸ” Security Checklist

- [ ] Change default passwords in `.env`
- [ ] Set strong `SECRET_KEY` in `.env`
- [ ] Set `DEBUG=False` in production
- [ ] Configure `ALLOWED_HOSTS` properly
- [ ] Enable HTTPS with SSL certificates
- [ ] Regular database backups
- [ ] Keep Docker images updated
- [ ] Monitor logs for suspicious activity

## ğŸ“š Additional Resources

- [Django Documentation](https://docs.djangoproject.com/)
- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [Nginx Documentation](https://nginx.org/en/docs/)
- [React Documentation](https://react.dev/)

## ğŸ¤ Support

For issues or questions:
1. Check the troubleshooting section above
2. Review logs: `./start.sh logs`
3. Check service status: `./start.sh status`

---

**Note**: This deployment setup is production-ready but can be further customized based on your specific requirements (e.g., cloud providers, orchestration tools like Kubernetes, etc.).

